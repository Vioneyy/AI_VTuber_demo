"""
F5-TTS-Thai Engine (Real Implementation)
âœ… à¸£à¸­à¸‡à¸£à¸±à¸š API à¸ˆà¸£à¸´à¸‡à¸‚à¸­à¸‡ F5-TTS-Thai
"""
import os
import numpy as np
import torch
import torchaudio
from io import BytesIO
import logging

logger = logging.getLogger(__name__)

class F5TTSThai:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.use_reference = os.getenv("F5_TTS_USE_REFERENCE", "false").lower() == "true"
        self.ref_audio_path = os.getenv("TTS_REFERENCE_WAV", "ref_audio.wav")
        self.ref_text = os.getenv("F5_TTS_REF_TEXT", "")
        self.speed = float(os.getenv("F5_TTS_SPEED", "1.0"))
        self.steps = int(os.getenv("F5_TTS_STEPS", "32"))  # default 32
        self.cfg_strength = float(os.getenv("F5_TTS_CFG_STRENGTH", "2.0"))
        self.sample_rate = int(os.getenv("F5_TTS_SAMPLE_RATE", "24000"))
        
        logger.info(f"F5-TTS-Thai: device={self.device}, speed={self.speed}, steps={self.steps}")
        
        try:
            # âœ… à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡: à¹ƒà¸Šà¹‰ TTS class à¸ˆà¸²à¸ f5_tts_th.tts
            from f5_tts_th.tts import TTS
            
            logger.info("ðŸ“¦ à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸” F5-TTS-Thai model...")
            
            # à¹‚à¸«à¸¥à¸” model à¸”à¹‰à¸§à¸¢ TTS class
            self.tts = TTS(model="v1")  # à¹ƒà¸Šà¹‰ model v1 à¸•à¸²à¸¡ Hugging Face
            
            logger.info("âœ… F5-TTS-Thai à¹‚à¸«à¸¥à¸”à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

            
        except ImportError as e:
            logger.error(f"âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸– import F5-TTS-Thai: {e}")
            logger.error("à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¸”à¹‰à¸§à¸¢: pip install f5-tts-thai")
            raise
        except Exception as e:
            logger.error(f"âŒ à¹‚à¸«à¸¥à¸” F5-TTS-Thai à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {e}")
            raise

    def set_use_reference(self, use_ref: bool):
        """à¹€à¸›à¸´à¸”/à¸›à¸´à¸” reference runtime"""
        self.use_reference = use_ref
        logger.info(f"F5-TTS: use_reference = {use_ref}")

    def _sanitize_text(self, text: str) -> str:
        """à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡"""
        text = text.strip()
        import re
        # à¸¥à¸š emoji à¹à¸¥à¸° special characters
        text = re.sub(r'[^\w\s\u0E00-\u0E7F.,!?-]', '', text)
        return text

    def synthesize(self, text: str) -> bytes:
        """
        à¸ªà¸±à¸‡à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
        """
        try:
            text = self._sanitize_text(text)
            
            if not text:
                logger.warning("à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸§à¹ˆà¸²à¸‡")
                return self._generate_silence(1.0)

            logger.info(f"ðŸŽ¤ F5-TTS-Thai à¸à¸³à¸¥à¸±à¸‡à¸ªà¸±à¸‡à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ: {text[:50]}...")

            # à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² reference
            if self.use_reference and os.path.exists(self.ref_audio_path) and self.ref_text:
                ref_audio = self.ref_audio_path
                ref_text = self.ref_text
                logger.info(f"ðŸŽ™ï¸ à¹ƒà¸Šà¹‰ reference: {ref_text[:30]}...")
            else:
                # à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ reference - à¹ƒà¸Šà¹‰à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸‡à¸µà¸¢à¸š
                ref_audio = self._get_silent_reference()
                ref_text = ""
                logger.info("ðŸ”‡ à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ reference")

            # à¹€à¸£à¸µà¸¢à¸ TTS.infer à¸•à¸²à¸¡ API à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
            generated_audio = self.tts.infer(
                ref_audio=ref_audio,
                ref_text=ref_text,
                gen_text=text,
                step=self.steps,
                cfg=self.cfg_strength,
                speed=self.speed
            )

            # Clean audio
            audio_data = self._clean_audio(generated_audio)
            
            # à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ WAV bytes
            wav_bytes = self._to_wav_bytes(audio_data, self.sample_rate)
            
            logger.info(f"âœ… à¸ªà¸±à¸‡à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {len(wav_bytes)} bytes")
            return wav_bytes

        except Exception as e:
            logger.error(f"âŒ F5-TTS synthesis error: {e}", exc_info=True)
            return self._generate_silence(2.0)

    def _clean_audio(self, audio: np.ndarray) -> np.ndarray:
        """à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¹€à¸ªà¸µà¸¢à¸‡"""
        # à¸¥à¸š NaN/Inf
        audio = np.nan_to_num(audio, nan=0.0, posinf=0.0, neginf=0.0)
        
        # Clip
        audio = np.clip(audio, -1.0, 1.0)
        
        # RMS Normalize
        rms = np.sqrt(np.mean(audio**2))
        if rms > 1e-6:
            target_rms = 0.1
            audio = audio * (target_rms / rms)
        
        # Fade in/out (10ms)
        fade_samples = int(self.sample_rate * 0.01)
        if len(audio) > fade_samples * 2:
            fade_in = np.linspace(0, 1, fade_samples)
            fade_out = np.linspace(1, 0, fade_samples)
            audio[:fade_samples] *= fade_in
            audio[-fade_samples:] *= fade_out
        
        return audio

    def _to_wav_bytes(self, audio: np.ndarray, sample_rate: int) -> bytes:
        """à¹à¸›à¸¥à¸‡ numpy array à¹€à¸›à¹‡à¸™ WAV bytes"""
        buffer = BytesIO()
        
        audio_tensor = torch.from_numpy(audio).float()
        if audio_tensor.dim() == 1:
            audio_tensor = audio_tensor.unsqueeze(0)
        
        torchaudio.save(buffer, audio_tensor, sample_rate, format="wav")
        buffer.seek(0)
        
        return buffer.read()

    def _get_silent_reference(self) -> str:
        """à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹€à¸‡à¸µà¸¢à¸šà¸ªà¸³à¸«à¸£à¸±à¸š reference"""
        silent_path = "temp_silent_ref.wav"
        
        if not os.path.exists(silent_path):
            duration = 0.5
            silent_audio = np.zeros(int(self.sample_rate * duration), dtype=np.float32)
            silent_tensor = torch.from_numpy(silent_audio).unsqueeze(0)
            torchaudio.save(silent_path, silent_tensor, self.sample_rate)
            logger.info(f"à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹€à¸‡à¸µà¸¢à¸š: {silent_path}")
        
        return silent_path

    def _generate_silence(self, duration: float) -> bytes:
        """à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸‡à¸µà¸¢à¸š"""
        silent_audio = np.zeros(int(self.sample_rate * duration), dtype=np.float32)
        return self._to_wav_bytes(silent_audio, self.sample_rate)