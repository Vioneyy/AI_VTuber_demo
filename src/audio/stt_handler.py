"""
‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Speech-to-Text ‡∏î‡πâ‡∏ß‡∏¢ Whisper.cpp
‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: src/audio/stt_handler.py (‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà stt_whispercpp.py)
"""

import asyncio
import subprocess
import tempfile
import os
import wave
import numpy as np
from pathlib import Path
from typing import Optional
import importlib

import sys
sys.path.append('..')
from core.config import config

class STTHandler:
    """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Speech-to-Text"""
    
    def __init__(self):
        self.whisper_bin = Path(config.stt.whisper_bin_path)
        self.model_path = Path(config.stt.whisper_model_path)
        self.total_processed = 0
        self._py_whisper_model = None
        self._py_whisper_model_name = os.getenv("PY_WHISPER_MODEL", "medium")
        # ‡∏õ‡∏¥‡∏î fp16 ‡πÄ‡∏õ‡πá‡∏ô‡∏î‡∏µ‡∏ü‡∏≠‡∏•‡∏ï‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á error ‡∏ö‡∏ô GPU/‡πÑ‡∏î‡∏£‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ö‡∏≤‡∏á‡∏£‡∏∏‡πà‡∏ô
        self._py_whisper_fp16 = (os.getenv("PY_WHISPER_FP16", "false").lower() in ("1", "true", "yes"))
        self._py_whisper_fallback_warned = False
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå
        if not self.whisper_bin.exists():
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Whisper.cpp: {self.whisper_bin}")
        if not self.model_path.exists():
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: {self.model_path}")

        # ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ whisper.cpp ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Python Whisper ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤
        try:
            if not self.whisper_bin.exists():
                self._preload_python_whisper()
        except Exception as e:
            # ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏û‡∏£‡∏≤‡∏∞ fallback ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ preload Python Whisper: {e}")
    
    async def transcribe_audio(self, audio_data: bytes, sample_rate: int = 16000) -> Optional[str]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        Args:
            audio_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á (bytes)
            sample_rate: sample rate (Hz)
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
        """
        try:
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                tmp_path = tmp_file.name
                self._save_wav(tmp_path, audio_data, sample_rate)
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Whisper.cpp ‡∏´‡∏£‡∏∑‡∏≠ fallback ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ Python Whisper
            text: Optional[str] = None
            if self.whisper_bin.exists():
                text = await self._run_whisper(tmp_path)
                # ‡∏ñ‡πâ‡∏≤ Whisper.cpp ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏•‡∏≠‡∏á fallback ‡πÅ‡∏ö‡∏ö Python ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
                if not text:
                    print("üîÅ Whisper.cpp ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏• ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Python Whisper ‡πÅ‡∏ó‡∏ô")
                    text = await self._run_python_whisper(tmp_path)
            else:
                if not self._py_whisper_fallback_warned:
                    print("üîÅ ‡πÉ‡∏ä‡πâ Python Whisper fallback (‡πÑ‡∏°‡πà‡∏û‡∏ö Whisper.cpp)")
                    self._py_whisper_fallback_warned = True
                text = await self._run_python_whisper(tmp_path)
            
            # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            try:
                os.unlink(tmp_path)
            except:
                pass
            
            if text:
                self.total_processed += 1
                print(f"üé§ STT Result: '{text}'")
                return text
            
            return None
            
        except Exception as e:
            print(f"‚ùå STT Error: {e}")
            return None
    
    async def _run_whisper(self, audio_path: str) -> Optional[str]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Whisper.cpp"""
        try:
            cmd = [
                str(self.whisper_bin),
                "-m", str(self.model_path),
                "-f", audio_path,
                "-l", config.stt.language,
                "-t", str(config.stt.threads),
                "-ng", str(config.stt.n_gpu_layers),
                "-nt",  # no timestamps
                "-otxt"  # output text only
            ]
            
            # ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            # ‡∏£‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=config.stt.timeout_ms / 1000
                )
            except asyncio.TimeoutError:
                process.kill()
                print("‚è∞ Whisper timeout")
                return None
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            if process.returncode == 0:
                # Whisper.cpp output ‡πÑ‡∏ü‡∏•‡πå .txt
                txt_path = audio_path + ".txt"
                if Path(txt_path).exists():
                    with open(txt_path, 'r', encoding='utf-8') as f:
                        text = f.read().strip()
                    os.unlink(txt_path)
                    return text if text else None
            
            return None
            
        except Exception as e:
            print(f"‚ùå Whisper Error: {e}")
            return None

    async def _run_python_whisper(self, audio_path: str) -> Optional[str]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Python Whisper (openai-whisper) ‡πÅ‡∏ö‡∏ö non-blocking ‡∏î‡πâ‡∏ß‡∏¢ to_thread"""
        def _transcribe_blocking() -> Optional[str]:
            try:
                whisper = importlib.import_module("whisper")
            except Exception:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ Python Whisper (openai-whisper). ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢: pip install -U openai-whisper")
                return None

            try:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU ‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á error ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ CUDA
                try:
                    import torch  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ CUDA ‡πÅ‡∏ö‡∏ö runtime
                    use_gpu = torch.cuda.is_available()
                except Exception:
                    use_gpu = False
                device = "cuda" if use_gpu else "cpu"
                # ‡πÅ‡∏Ñ‡∏ä‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ã‡πâ‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
                if self._py_whisper_model is None:
                    # ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å preload ‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
                    print(f"‚¨áÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Python Whisper: {self._py_whisper_model_name} ({device})")
                    self._py_whisper_model = whisper.load_model(self._py_whisper_model_name, device=device)

                # ‡πÉ‡∏ä‡πâ fp16 ‡∏ï‡∏≤‡∏° ENV ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏î‡∏µ‡∏ü‡∏≠‡∏•‡∏ï‡πå False ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
                fp16 = bool(self._py_whisper_fp16 and use_gpu)
                try:
                    result = self._py_whisper_model.transcribe(
                        audio_path,
                        language=config.stt.language,
                        fp16=fp16,
                    )
                except Exception as e:
                    # ‡πÅ‡∏Å‡πâ‡πÄ‡∏Ñ‡∏™ GPU shape mismatch ‡πÇ‡∏î‡∏¢ retry ‡πÅ‡∏ö‡∏ö fp16=False ‡πÅ‡∏•‡∏∞/‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ CPU
                    err_msg = str(e)
                    print(f"‚ö†Ô∏è Python Whisper Error (initial): {err_msg}")
                    try:
                        # Retry ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 1: ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö fp16=False ‡∏ö‡∏ô‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡πÄ‡∏î‡∏¥‡∏°
                        result = self._py_whisper_model.transcribe(
                            audio_path,
                            language=config.stt.language,
                            fp16=False,
                        )
                    except Exception as e2:
                        print(f"‚ö†Ô∏è Retry fp32 ‡∏ö‡∏ô {device} ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e2}")
                        # Retry ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2: ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ CPU ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ GPU ‡∏≠‡∏¢‡∏π‡πà
                        try:
                            if use_gpu:
                                cpu_model = whisper.load_model(self._py_whisper_model_name, device="cpu")
                                result = cpu_model.transcribe(
                                    audio_path,
                                    language=config.stt.language,
                                    fp16=False,
                                )
                            else:
                                raise e2
                        except Exception as e3:
                            print(f"‚ùå Python Whisper Error (retries failed): {e3}")
                            return None

                text = (result.get("text") or "").strip()
                return text if text else None
            except Exception as e:
                print(f"‚ùå Python Whisper Error: {e}")
                return None

        # ‡∏£‡∏±‡∏ô‡∏á‡∏≤‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö off-thread ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ö‡∏•‡πá‡∏≠‡∏Å event loop
        return await asyncio.to_thread(_transcribe_blocking)
    
    def _save_wav(self, path: str, audio_data: bytes, sample_rate: int):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå WAV"""
        # ‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ö‡∏±‡∏ü‡πÄ‡∏ü‡∏≠‡∏£‡πå: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏π‡πà‡∏Ç‡∏≠‡∏á‡πÑ‡∏ö‡∏ï‡πå ‡πÉ‡∏´‡πâ‡πÅ‡∏û‡∏î 0 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á wave error
        if len(audio_data) % 2 != 0:
            audio_data = audio_data + b"\x00"
        # ‡πÅ‡∏õ‡∏•‡∏á bytes ‡πÄ‡∏õ‡πá‡∏ô numpy array (mono 16-bit)
        audio_np = np.frombuffer(audio_data, dtype=np.int16)
        # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å: downsample ‡πÄ‡∏õ‡πá‡∏ô 16k ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏†‡∏≤‡∏£‡∏∞ ffmpeg/whisper (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ scipy)
        try:
            if sample_rate != 16000:
                from scipy.signal import resample_poly
                # ‡πÉ‡∏ä‡πâ polyphase resampling ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
                audio_np = resample_poly(audio_np.astype(np.float32), 1, int(sample_rate/16000)).astype(np.int16)
                sample_rate = 16000
        except Exception:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ scipy ‡πÉ‡∏´‡πâ‡∏Ñ‡∏á sample_rate ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ ‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡∏à‡∏∞ resample ‡πÄ‡∏≠‡∏á
            pass
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô WAV
        with wave.open(path, 'wb') as wav_file:
            wav_file.setnchannels(1)  # mono
            wav_file.setsampwidth(2)  # 16-bit
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_np.tobytes())
    
    async def transcribe_file(self, file_path: str) -> Optional[str]:
        """‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        if not Path(file_path).exists():
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {file_path}")
            return None
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Whisper.cpp ‡∏´‡∏£‡∏∑‡∏≠ fallback Python
        if self.whisper_bin.exists():
            text = await self._run_whisper(file_path)
            if text:
                return text
            print("üîÅ Whisper.cpp ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏• ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Python Whisper ‡πÅ‡∏ó‡∏ô")
            return await self._run_python_whisper(file_path)
        else:
            print("üîÅ ‡πÉ‡∏ä‡πâ Python Whisper fallback (‡πÑ‡∏°‡πà‡∏û‡∏ö Whisper.cpp)")
            return await self._run_python_whisper(file_path)
    
    def get_stats(self):
        """‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥"""
        return {
            "total_processed": self.total_processed
        }

    # ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô: ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Python Whisper ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
    def _preload_python_whisper(self):
        try:
            whisper = importlib.import_module("whisper")
        except Exception:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ Python Whisper (openai-whisper). ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢: pip install -U openai-whisper")
            return

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU ‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å
        try:
            import torch
            use_gpu = torch.cuda.is_available()
        except Exception:
            use_gpu = False
        device = "cuda" if use_gpu else "cpu"

        if self._py_whisper_model is None:
            print(f"‚¨áÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Python Whisper: {self._py_whisper_model_name} ({device})")
            self._py_whisper_model = whisper.load_model(self._py_whisper_model_name, device=device)

# Global STT handler
stt_handler = STTHandler()