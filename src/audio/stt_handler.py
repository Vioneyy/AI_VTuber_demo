"""
‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Speech-to-Text ‡∏î‡πâ‡∏ß‡∏¢ Whisper.cpp
‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: src/audio/stt_handler.py (‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà stt_whispercpp.py)
"""

import asyncio
import subprocess
import tempfile
import os
import wave
import numpy as np
from pathlib import Path
from typing import Optional
import importlib

import sys
sys.path.append('..')
from core.config import config

class STTHandler:
    """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Speech-to-Text"""
    
    def __init__(self):
        self.whisper_bin = Path(config.stt.whisper_bin_path)
        self.model_path = Path(config.stt.whisper_model_path)
        self.total_processed = 0
        self._py_whisper_model = None
        self._py_whisper_model_name = os.getenv("PY_WHISPER_MODEL", "medium")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå
        if not self.whisper_bin.exists():
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Whisper.cpp: {self.whisper_bin}")
        if not self.model_path.exists():
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: {self.model_path}")
    
    async def transcribe_audio(self, audio_data: bytes, sample_rate: int = 16000) -> Optional[str]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        Args:
            audio_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á (bytes)
            sample_rate: sample rate (Hz)
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
        """
        try:
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                tmp_path = tmp_file.name
                self._save_wav(tmp_path, audio_data, sample_rate)
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Whisper.cpp ‡∏´‡∏£‡∏∑‡∏≠ fallback ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ Python Whisper
            text: Optional[str] = None
            if self.whisper_bin.exists():
                text = await self._run_whisper(tmp_path)
                # ‡∏ñ‡πâ‡∏≤ Whisper.cpp ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏•‡∏≠‡∏á fallback ‡πÅ‡∏ö‡∏ö Python ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
                if not text:
                    print("üîÅ Whisper.cpp ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏• ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Python Whisper ‡πÅ‡∏ó‡∏ô")
                    text = await self._run_python_whisper(tmp_path)
            else:
                print("üîÅ ‡πÉ‡∏ä‡πâ Python Whisper fallback (‡πÑ‡∏°‡πà‡∏û‡∏ö Whisper.cpp)")
                text = await self._run_python_whisper(tmp_path)
            
            # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            try:
                os.unlink(tmp_path)
            except:
                pass
            
            if text:
                self.total_processed += 1
                print(f"üé§ STT Result: '{text}'")
                return text
            
            return None
            
        except Exception as e:
            print(f"‚ùå STT Error: {e}")
            return None
    
    async def _run_whisper(self, audio_path: str) -> Optional[str]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Whisper.cpp"""
        try:
            cmd = [
                str(self.whisper_bin),
                "-m", str(self.model_path),
                "-f", audio_path,
                "-l", config.stt.language,
                "-t", str(config.stt.threads),
                "-ng", str(config.stt.n_gpu_layers),
                "-nt",  # no timestamps
                "-otxt"  # output text only
            ]
            
            # ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            # ‡∏£‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=config.stt.timeout_ms / 1000
                )
            except asyncio.TimeoutError:
                process.kill()
                print("‚è∞ Whisper timeout")
                return None
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            if process.returncode == 0:
                # Whisper.cpp output ‡πÑ‡∏ü‡∏•‡πå .txt
                txt_path = audio_path + ".txt"
                if Path(txt_path).exists():
                    with open(txt_path, 'r', encoding='utf-8') as f:
                        text = f.read().strip()
                    os.unlink(txt_path)
                    return text if text else None
            
            return None
            
        except Exception as e:
            print(f"‚ùå Whisper Error: {e}")
            return None

    async def _run_python_whisper(self, audio_path: str) -> Optional[str]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Python Whisper (openai-whisper) ‡πÅ‡∏ö‡∏ö non-blocking ‡∏î‡πâ‡∏ß‡∏¢ to_thread"""
        def _transcribe_blocking() -> Optional[str]:
            try:
                whisper = importlib.import_module("whisper")
            except Exception:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ Python Whisper (openai-whisper). ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢: pip install -U openai-whisper")
                return None

            try:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU ‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á error ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ CUDA
                try:
                    import torch  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ CUDA ‡πÅ‡∏ö‡∏ö runtime
                    use_gpu = torch.cuda.is_available()
                except Exception:
                    use_gpu = False
                device = "cuda" if use_gpu else "cpu"
                # ‡πÅ‡∏Ñ‡∏ä‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ã‡πâ‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
                if self._py_whisper_model is None:
                    print(f"‚¨áÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Python Whisper: {self._py_whisper_model_name} ({device})")
                    self._py_whisper_model = whisper.load_model(self._py_whisper_model_name, device=device)

                # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ fp16 ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ GPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
                fp16 = use_gpu
                result = self._py_whisper_model.transcribe(audio_path, language=config.stt.language, fp16=fp16)
                text = (result.get("text") or "").strip()
                return text if text else None
            except Exception as e:
                print(f"‚ùå Python Whisper Error: {e}")
                return None

        # ‡∏£‡∏±‡∏ô‡∏á‡∏≤‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö off-thread ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ö‡∏•‡πá‡∏≠‡∏Å event loop
        return await asyncio.to_thread(_transcribe_blocking)
    
    def _save_wav(self, path: str, audio_data: bytes, sample_rate: int):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå WAV"""
        # ‡πÅ‡∏õ‡∏•‡∏á bytes ‡πÄ‡∏õ‡πá‡∏ô numpy array
        audio_np = np.frombuffer(audio_data, dtype=np.int16)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô WAV
        with wave.open(path, 'wb') as wav_file:
            wav_file.setnchannels(1)  # mono
            wav_file.setsampwidth(2)  # 16-bit
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_np.tobytes())
    
    async def transcribe_file(self, file_path: str) -> Optional[str]:
        """‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        if not Path(file_path).exists():
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {file_path}")
            return None
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Whisper.cpp ‡∏´‡∏£‡∏∑‡∏≠ fallback Python
        if self.whisper_bin.exists():
            text = await self._run_whisper(file_path)
            if text:
                return text
            print("üîÅ Whisper.cpp ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏• ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Python Whisper ‡πÅ‡∏ó‡∏ô")
            return await self._run_python_whisper(file_path)
        else:
            print("üîÅ ‡πÉ‡∏ä‡πâ Python Whisper fallback (‡πÑ‡∏°‡πà‡∏û‡∏ö Whisper.cpp)")
            return await self._run_python_whisper(file_path)
    
    def get_stats(self):
        """‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥"""
        return {
            "total_processed": self.total_processed
        }

# Global STT handler
stt_handler = STTHandler()