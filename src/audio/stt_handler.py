"""
STT Handler - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Tensor Error ‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏¥‡πà‡∏á
"""
import numpy as np
import torch
import logging
import asyncio
from pathlib import Path
import subprocess
import tempfile
import soundfile as sf
from typing import Optional, Tuple
import os

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤ config ‡∏à‡∏≤‡∏Å .env ‡∏ú‡πà‡∏≤‡∏ô core.config ‡∏ó‡∏µ‡πà‡∏ä‡∏µ‡πâ‡∏û‡∏≤‡∏ò .env ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
try:
    from core.config import config as AppConfig
except Exception:
    AppConfig = None

logger = logging.getLogger(__name__)

class STTHandler:
    """
    Speech-to-Text Handler
    ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤:
    1. Tensor dimension mismatch (size a != size b)
    2. ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏¥‡πà‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠ error
    3. Fallback ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á whisper.cpp ‡πÅ‡∏•‡∏∞ Python Whisper
    """
    
    def __init__(
        self,
        model_name: str = "base",
        device: str = "cuda",
        language: str = "th",
        use_cpp: bool = False,
        cpp_binary_path: Optional[str] = None,
        cpp_model_path: Optional[str] = None
    ):
        """
        Args:
            model_name: Whisper model (tiny/base/small/medium/large)
            device: Device (cpu/cuda)
            language: Language (th/en/auto)
            use_cpp: ‡πÉ‡∏ä‡πâ whisper.cpp ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            cpp_binary_path: Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á whisper.cpp binary
            cpp_model_path: Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á whisper.cpp model
        """
        self.model_name = model_name
        self.device = device
        self.language = language
        
        # Decode options ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Æ‡∏±‡∏•‡∏•‡∏π‡∏ã‡∏¥‡πÄ‡∏ô‡∏ä‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        # ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏•‡∏¥‡∏õ‡∏™‡∏±‡πâ‡∏ô‡∏à‡∏≤‡∏Å Discord
        self.decode_options = {
            # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏™‡∏°‡∏≠ (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏ñ‡πâ‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô 'auto')
            "language": self.language if self.language != "auto" else None,
            "task": "transcribe",
            # ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏î‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô
            "temperature": 0.0,
            # ‡πÉ‡∏ä‡πâ beam search ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ö‡∏≤ ‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏Ñ‡∏á‡∏ß‡∏≤
            "beam_size": 5,
            "best_of": 1,
            "patience": 1.0,
            # ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏≠‡∏Ñ‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ (‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á‡∏û‡∏π‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¥‡∏™‡∏£‡∏∞)
            "condition_on_previous_text": False,
            # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ timestamps ‡πÅ‡∏•‡∏∞ suppress ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            "without_timestamps": True,
            "suppress_blank": True,
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ compression ratio ‡∏™‡∏π‡∏á (‡∏°‡∏±‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ù‡∏≠‡∏¢/‡∏Å‡πä‡∏≠‡∏ö‡πÄ‡∏ö‡∏•)
            "compression_ratio_threshold": 2.4,
            # ‡∏õ‡∏£‡∏±‡∏ö threshold ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏ì‡∏∞‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
            "logprob_threshold": -1.0,
            "no_speech_threshold": 0.45,
            # prompt ‡πÄ‡∏û‡∏∑‡πà‡∏≠ bias ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÑ‡∏ó‡∏¢‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
            "initial_prompt": "‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ñ‡πà‡∏∞",
        }
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤ STT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏£‡∏ß‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô ~10s ‡∏ï‡πà‡∏≠‡∏£‡∏≠‡∏ö
        self.timeout_seconds = 7
        try:
            if AppConfig is not None:
                self.timeout_seconds = int(getattr(AppConfig, 'WHISPER_TIMEOUT_SECONDS', self.timeout_seconds))
        except Exception:
            pass
        
        # Check CUDA
        if device == "cuda" and not torch.cuda.is_available():
            logger.warning("CUDA not available, using CPU")
            self.device = "cpu"
        
        # Whisper.cpp
        self.use_cpp = use_cpp
        self.cpp_available = False
        
        if use_cpp:
            self.cpp_available = self._check_cpp_available(
                cpp_binary_path,
                cpp_model_path
            )
            if self.cpp_available:
                self.cpp_binary_path = Path(cpp_binary_path)
                self.cpp_model_path = Path(cpp_model_path)
                logger.info(f"‚úÖ ‡πÉ‡∏ä‡πâ Whisper.cpp: {cpp_binary_path}")
            else:
                logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Whisper.cpp: {cpp_binary_path}")
                logger.info("üîÅ ‡πÉ‡∏ä‡πâ Python Whisper fallback")
        
        # Load Python Whisper
        self.model = None
        if not self.cpp_available:
            self.model = self._load_python_whisper()
        
        # Stats
        self.total_transcriptions = 0
        self.failed_transcriptions = 0
    
    def _check_cpp_available(
        self,
        binary_path: Optional[str],
        model_path: Optional[str]
    ) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö whisper.cpp"""
        try:
            if not binary_path or not model_path:
                return False
            
            binary = Path(binary_path)
            model = Path(model_path)
            
            if not binary.exists():
                logger.debug(f"Binary not found: {binary}")
                return False
            
            if not model.exists():
                logger.debug(f"Model not found: {model}")
                return False
            
            # Test run
            result = subprocess.run(
                [str(binary), "--help"],
                capture_output=True,
                timeout=5
            )
            
            return result.returncode == 0
            
        except Exception as e:
            logger.debug(f"Whisper.cpp check failed: {e}")
            return False
    
    def _load_python_whisper(self):
        """‡πÇ‡∏´‡∏•‡∏î Python Whisper"""
        try:
            import whisper
            
            logger.info(f"‚¨áÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Python Whisper: {self.model_name} ({self.device})")
            model = whisper.load_model(self.model_name, device=self.device)
            logger.info("‚úÖ Python Whisper ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            
            return model
            
        except Exception as e:
            logger.error(f"‚ùå ‡πÇ‡∏´‡∏•‡∏î Python Whisper ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}", exc_info=True)
            raise
    
    async def transcribe(
        self,
        audio_data: bytes,
        sample_rate: int = 48000
    ) -> Optional[str]:
        """
        Transcribe audio to text
        
        Args:
            audio_data: Raw audio bytes (‡∏à‡∏≤‡∏Å Discord)
            sample_rate: Sample rate (Discord = 48000)
        
        Returns:
            Transcribed text or None
        """
        try:
            self.total_transcriptions += 1
            
            # 1. Preprocess audio (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç tensor dimension issues)
            audio_np = self._preprocess_audio(audio_data, sample_rate)
            
            if audio_np is None or len(audio_np) == 0:
                logger.warning("‚ö†Ô∏è Audio preprocessing failed")
                self.failed_transcriptions += 1
                return None
            
            # 2. Validate audio
            if not self._validate_audio(audio_np):
                logger.warning("‚ö†Ô∏è Audio validation failed")
                self.failed_transcriptions += 1
                return None
            
            # 3. Transcribe
            if self.cpp_available:
                logger.debug("üîÅ ‡πÉ‡∏ä‡πâ Whisper.cpp")
                text = await self._transcribe_cpp(audio_np)
                if text:
                    return text
                logger.warning("‚ö†Ô∏è Whisper.cpp ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß, ‡πÉ‡∏ä‡πâ Python Whisper")
            
            # Fallback to Python Whisper
            logger.debug("üîÅ ‡πÉ‡∏ä‡πâ Python Whisper fallback (‡πÑ‡∏°‡πà‡∏û‡∏ö Whisper.cpp)")
            text = await self._transcribe_python(audio_np)
            
            return text
            
        except Exception as e:
            logger.error(f"‚ùå Transcription failed: {e}", exc_info=True)
            self.failed_transcriptions += 1
            return None

    async def transcribe_audio(
        self,
        audio_data: bytes,
        sample_rate: int = 48000
    ) -> Optional[str]:
        """alias ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö main.py/Discord adapter"""
        return await self.transcribe(audio_data, sample_rate)
    
    def _preprocess_audio(
        self,
        audio_bytes: bytes,
        source_sr: int
    ) -> Optional[np.ndarray]:
        """
        Preprocess audio ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Whisper
        ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ tensor dimension mismatch
        """
        try:
            # 1. Convert bytes to numpy (Discord = int16 PCM)
            audio_np = np.frombuffer(audio_bytes, dtype=np.int16)
            
            if len(audio_np) == 0:
                return None
            
            # 2. Convert to float32 [-1, 1]
            audio_np = audio_np.astype(np.float32) / 32768.0
            
            # 3. Channel handling
            # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô VoiceRecvClient ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Discord PCM ‡πÄ‡∏õ‡πá‡∏ô mono 48kHz
            # ‡πÄ‡∏î‡∏¥‡∏°‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° reshape ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πÄ‡∏ï‡∏£‡∏¥‡πÇ‡∏≠‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç len%2==0 ‡∏ã‡∏∂‡πà‡∏á‡∏ó‡∏≥‡πÉ‡∏´‡πâ mono ‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
            # ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô mono ‡πÇ‡∏î‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á tensor mismatch
            # ‡∏´‡∏≤‡∏Å‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏™‡πÄ‡∏ï‡∏£‡∏¥‡πÇ‡∏≠ ‡∏Ñ‡∏ß‡∏£‡∏™‡πà‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å adapter ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ heuristic ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤
            
            # 4. Pre-filter to reduce hiss/rumble before resample
            try:
                from scipy.signal import butter, filtfilt
                # Bandpass ~80 Hz‚Äì8 kHz (typical speech band)
                nyq = 0.5 * float(source_sr)
                low = 80.0 / nyq
                high = 8000.0 / nyq
                if 0.0 < low < high < 1.0:
                    b, a = butter(4, [low, high], btype='band')
                    audio_np = filtfilt(b, a, audio_np).astype(np.float32)
            except Exception:
                # ‡∏´‡∏≤‡∏Å‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ
                pass

            # 5. Resample to 16kHz (Whisper requirement) ‡∏î‡πâ‡∏ß‡∏¢ polyphase ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏≠‡∏≤‡∏£‡πå‡∏ï‡∏¥‡πÅ‡∏ü‡∏Å‡∏ï‡πå
            if source_sr != 16000:
                try:
                    from scipy.signal import resample_poly
                    audio_np = resample_poly(audio_np, 16000, source_sr).astype(np.float32)
                except Exception:
                    from scipy import signal as scipy_signal
                    num_samples = int(len(audio_np) * 16000 / source_sr)
                    audio_np = scipy_signal.resample(audio_np, num_samples).astype(np.float32)
            
            # 6. Normalize ‡∏î‡πâ‡∏ß‡∏¢ RMS ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢ noise ‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            try:
                rms = float(np.sqrt(np.mean(audio_np**2)) + 1e-8)
                target_rms = 0.1  # ‚âà -20 dBFS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö STT
                gain = min(target_rms / rms, 3.0)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Ç‡∏¢‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡πÄ‡∏Å‡∏¥‡∏ô
                audio_np = (audio_np * gain).astype(np.float32)
            except Exception:
                # Fallback ‡πÄ‡∏õ‡πá‡∏ô peak normalize ‡πÅ‡∏ö‡∏ö‡∏≠‡πà‡∏≠‡∏ô
                max_val = np.abs(audio_np).max()
                if max_val > 0:
                    audio_np = (audio_np * (0.8 / max_val)).astype(np.float32)
            
            # 7. Remove silence ‡∏î‡πâ‡∏ß‡∏¢ threshold ‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å‡∏ï‡∏≤‡∏° RMS
            try:
                dyn_th = max(0.01, 0.5 * float(np.sqrt(np.mean(audio_np**2))))
                audio_np = self._remove_silence(audio_np, threshold=dyn_th)
            except Exception:
                audio_np = self._remove_silence(audio_np)
            
            # 8. Fix length (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç! ‡πÅ‡∏Å‡πâ tensor dimension error)
            audio_np = self._fix_length_for_whisper(audio_np)
            
            # 9. Final validation
            if len(audio_np) == 0:
                return None
            
            # Ensure float32
            audio_np = audio_np.astype(np.float32)
            
            return audio_np
            
        except Exception as e:
            logger.error(f"Audio preprocessing error: {e}", exc_info=True)
            return None
    
    def _remove_silence(
        self,
        audio: np.ndarray,
        threshold: float = 0.01
    ) -> np.ndarray:
        """‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏≠‡∏≠‡∏Å"""
        try:
            # ‡∏´‡∏≤ energy
            window_size = int(0.02 * 16000)  # 20ms
            hop_size = window_size // 2
            
            if len(audio) < window_size:
                return audio
            
            energy = np.array([
                np.sqrt(np.mean(audio[i:i+window_size]**2))
                for i in range(0, len(audio) - window_size, hop_size)
            ])
            
            # ‡∏´‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            voice_mask = energy > threshold
            
            if not voice_mask.any():
                return audio
            
            # Expand mask
            voice_indices = np.repeat(voice_mask, hop_size)
            voice_indices = voice_indices[:len(audio)]
            
            # Pad ‡∏ñ‡πâ‡∏≤‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
            if len(voice_indices) < len(audio):
                voice_indices = np.pad(
                    voice_indices,
                    (0, len(audio) - len(voice_indices)),
                    constant_values=True
                )
            
            # ‡∏ï‡∏±‡∏î‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏≠‡∏≠‡∏Å
            audio = audio[voice_indices]
            
            return audio
            
        except Exception as e:
            logger.warning(f"Silence removal failed: {e}")
            return audio
    
    def _fix_length_for_whisper(
        self,
        audio: np.ndarray,
        min_duration: float = 0.5,
        max_duration: float = 30.0
    ) -> np.ndarray:
        """
        ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö Whisper
        ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å! ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ tensor dimension error
        """
        try:
            sr = 16000
            min_samples = int(min_duration * sr)
            max_samples = int(max_duration * sr)
            
            current_samples = len(audio)
            
            # ‡∏ñ‡πâ‡∏≤‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ: pad ‡∏î‡πâ‡∏ß‡∏¢ zeros ‡πÉ‡∏´‡πâ‡∏ñ‡∏∂‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
            if current_samples < min_samples:
                padding = min_samples - current_samples
                logger.debug(
                    f"Audio too short: {current_samples/sr:.2f}s (min: {min_duration}s), "
                    f"padding {padding} samples"
                )
                audio = np.pad(audio, (0, padding), mode='constant', constant_values=0)
            
            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ: ‡∏ï‡∏±‡∏î
            if current_samples > max_samples:
                logger.debug(f"Audio too long: {current_samples/sr:.2f}s, trimming to {max_duration}s")
                audio = audio[:max_samples]
            
            # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç! Pad ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà Whisper ‡∏ä‡∏≠‡∏ö
            # Whisper ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏µ‡∏Å‡∏±‡∏ö audio ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ï‡πá‡∏°‡∏Ç‡∏≠‡∏á 0.02s (320 samples)
            target_length = ((len(audio) + 319) // 320) * 320
            
            if len(audio) < target_length:
                padding = target_length - len(audio)
                audio = np.pad(audio, (0, padding), mode='constant', constant_values=0)
            
            return audio
            
        except Exception as e:
            logger.error(f"Length fixing failed: {e}")
            return audio
    
    def _validate_audio(self, audio: np.ndarray) -> bool:
        """Validate audio"""
        try:
            # Check empty
            if len(audio) == 0:
                return False
            
            # Check duration
            duration = len(audio) / 16000
            if duration < 0.5:
                logger.debug(f"Audio too short: {duration:.2f}s")
                return False
            
            if duration > 30:
                logger.warning(f"Audio too long: {duration:.2f}s")
                return False
            
            # Check dtype
            if audio.dtype != np.float32:
                logger.warning(f"Invalid dtype: {audio.dtype}")
                return False
            
            # Check range
            if np.abs(audio).max() > 10:
                logger.warning(f"Audio out of range: {audio.min():.2f} to {audio.max():.2f}")
                return False
            
            # Check for NaN/Inf
            if np.isnan(audio).any() or np.isinf(audio).any():
                logger.error("Audio contains NaN or Inf")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Validation error: {e}")
            return False
    
    async def _transcribe_python(self, audio: np.ndarray) -> Optional[str]:
        """
        Transcribe ‡∏î‡πâ‡∏ß‡∏¢ Python Whisper
        ‡∏°‡∏µ retry logic ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ tensor errors
        """
        if self.model is None:
            logger.error("Python Whisper model not loaded")
            return None
        
        try:
            # ‡∏•‡∏≠‡∏á transcribe (‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î tensor error)
            loop = asyncio.get_event_loop()
            
            result = await asyncio.wait_for(
                loop.run_in_executor(
                    None,
                    self._transcribe_with_retry,
                    audio
                ),
                timeout=self.timeout_seconds
            )
            
            if result:
                text = result['text'].strip()
                if text:
                    logger.info(f"‚úÖ Transcribed: {text}")
                    return text
            
            logger.warning("‚ö†Ô∏è Empty transcription")
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Python Whisper error: {e}", exc_info=True)
            return None
    
    def _transcribe_with_retry(self, audio: np.ndarray) -> Optional[dict]:
        """
        Transcribe with retry logic
        ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç tensor dimension errors ‡πÇ‡∏î‡∏¢‡∏•‡∏≠‡∏á config ‡∏ï‡πà‡∏≤‡∏á‡πÜ
        """
        configs = [
            # Config 1: fp16 on GPU (default)
            {'fp16': True, 'device': self.device},
            
            # Config 2: fp32 on GPU
            {'fp16': False, 'device': self.device},
            
            # Config 3: CPU fallback
            {'fp16': False, 'device': 'cpu'}
        ]
        
        for i, config in enumerate(configs):
            try:
                logger.debug(f"Attempt {i+1}: fp16={config['fp16']}, device={config['device']}")
                
                # ‡πÉ‡∏ä‡πâ decode options ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏Æ‡∏±‡∏•‡∏•‡∏π‡∏ã‡∏¥‡πÄ‡∏ô‡∏ä‡∏±‡∏ô
                result = self.model.transcribe(
                    audio,
                    fp16=config['fp16'],
                    verbose=False,
                    **self.decode_options
                )
                
                return result
                
            except RuntimeError as e:
                error_msg = str(e)
                
                if "size of tensor" in error_msg:
                    logger.warning(f"‚ö†Ô∏è Attempt {i+1} failed: Tensor dimension mismatch")
                    
                    if i < len(configs) - 1:
                        logger.info(f"   üîÑ Retrying with different config...")
                        continue
                    else:
                        logger.error("‚ùå All retry attempts failed")
                        return None
                else:
                    logger.error(f"‚ùå Whisper error: {e}")
                    return None
                    
            except Exception as e:
                logger.error(f"‚ùå Unexpected error: {e}")
                return None
        
        return None
    
    async def _transcribe_cpp(self, audio: np.ndarray) -> Optional[str]:
        """Transcribe ‡∏î‡πâ‡∏ß‡∏¢ whisper.cpp"""
        try:
            # Save to temp file
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
                temp_path = Path(f.name)
            
            # Save audio
            sf.write(str(temp_path), audio, 16000, subtype='PCM_16')
            
            # Run whisper.cpp
            cmd = [
                str(self.cpp_binary_path),
                '-m', str(self.cpp_model_path),
                '-f', str(temp_path),
                '-l', self.language,
                '--output-txt',
                '--no-timestamps',
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° threads ‡πÅ‡∏•‡∏∞ beam size ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß/‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
                '-t', str(max(1, min(8, (os.cpu_count() or 1)))),
                '-bs', '5'
            ]
            
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None,
                lambda: subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=self.timeout_seconds
                )
            )
            
            # Clean up
            temp_path.unlink(missing_ok=True)
            
            if result.returncode == 0:
                text = result.stdout.strip()
                if text:
                    logger.info(f"‚úÖ Transcribed (cpp): {text}")
                    return text
            else:
                logger.error(f"whisper.cpp error: {result.stderr}")
            
            return None
            
        except Exception as e:
            logger.error(f"whisper.cpp transcription failed: {e}")
            return None
    
    def get_stats(self) -> dict:
        """‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥"""
        success_rate = 0
        if self.total_transcriptions > 0:
            success_rate = (
                (self.total_transcriptions - self.failed_transcriptions) 
                / self.total_transcriptions 
                * 100
            )
        
        return {
            'total': self.total_transcriptions,
            'failed': self.failed_transcriptions,
            'success_rate': f"{success_rate:.1f}%",
            'using_cpp': self.cpp_available
        }

# ===== Global singleton ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏≠‡∏õ =====
# ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏ô main.py: from audio.stt_handler import stt_handler
def _create_global_stt_handler() -> STTHandler:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå STTHandler ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å .env ‡∏ú‡πà‡∏≤‡∏ô Config"""
    # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
    model_name = "tiny"
    device = "cpu"
    language = "th"
    use_cpp = False
    cpp_bin = None
    cpp_model = None

    # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env ‡∏ú‡πà‡∏≤‡∏ô Config ‡∏´‡∏≤‡∏Å‡∏°‡∏µ
    try:
        if AppConfig is not None:
            model_name = getattr(AppConfig, 'WHISPER_MODEL', model_name)
            device = getattr(AppConfig, 'WHISPER_DEVICE', device)
            language = getattr(AppConfig, 'WHISPER_LANG', language)
            use_cpp = bool(getattr(AppConfig, 'WHISPER_CPP_ENABLED', False))
            cpp_bin = getattr(AppConfig, 'WHISPER_CPP_BIN_PATH', None)
            cpp_model = getattr(AppConfig, 'WHISPER_CPP_MODEL_PATH', None)
    except Exception:
        # ‡∏´‡∏≤‡∏Å‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏î‡∏µ‡∏ü‡∏≠‡∏•‡∏ï‡πå
        pass

    return STTHandler(
        model_name=model_name,
        device=device,
        language=language,
        use_cpp=use_cpp,
        cpp_binary_path=cpp_bin,
        cpp_model_path=cpp_model,
    )


# ‡∏™‡∏£‡πâ‡∏≤‡∏á singleton ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ñ‡∏π‡∏Å import
stt_handler: STTHandler = _create_global_stt_handler()

__all__ = ["STTHandler", "stt_handler"]