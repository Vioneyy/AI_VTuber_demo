"""
‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° VTube Studio - Fixed Jittering & Lip Sync
‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
1. ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡∏Å (jittering) ‡∏î‡πâ‡∏ß‡∏¢ delta threshold + rate limiting
2. ‡∏õ‡∏£‡∏±‡∏ö lip sync ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥
3. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£ transition idle ‡πÉ‡∏´‡πâ‡∏£‡∏≤‡∏ö‡∏£‡∏∑‡πà‡∏ô
"""

import asyncio
import websockets
import json
import random
import time
import logging
from typing import Dict, Optional, List
from dataclasses import dataclass
from enum import Enum
import numpy as np

logger = logging.getLogger(__name__)

class AnimationState(Enum):
    """‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß"""
    IDLE = "idle"
    LISTENING = "listening"
    THINKING = "thinking"
    SPEAKING = "speaking"

class SmoothValue:
    """‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•"""
    def __init__(
        self,
        initial_value: float = 0.0,
        smooth_factor: float = 0.15,
        max_delta: float = 0.08,
        snap_epsilon: float = 0.002,  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.001 ‚Üí 0.002 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î jitter
    ):
        self.current = initial_value
        self.target = initial_value
        self.smooth_factor = smooth_factor
        self.max_delta = max_delta
        self.snap_epsilon = snap_epsilon
    
    def set_target(self, value: float):
        self.target = value
    
    def update(self) -> float:
        diff = self.target - self.current
        
        # ‚úÖ Snap ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î oscillation
        if abs(diff) < self.snap_epsilon:
            self.current = self.target
            return self.current
        
        delta = diff * self.smooth_factor
        
        # ‚úÖ ‡∏à‡∏≥‡∏Å‡∏±‡∏î delta
        if self.max_delta is not None:
            delta = max(-self.max_delta, min(self.max_delta, delta))
        
        self.current += delta
        return self.current

class VTubeStudioController:
    """‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° VTube Studio ‡∏ú‡πà‡∏≤‡∏ô WebSocket"""
    
    def __init__(self):
        # ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô config ‡∏à‡∏≤‡∏Å core.config
        from core.config import config
        
        self.ws: Optional[websockets.WebSocketClientProtocol] = None
        self.authenticated = False
        self.auth_token: Optional[str] = config.vtube.plugin_token
        self.model_loaded = False
        self.model_id = None
        self.animation_task: Optional[asyncio.Task] = None
        self.state = AnimationState.IDLE
        self.running = False
        
        # Available parameters
        self.available_parameters: Dict[str, Dict] = {}
        
        # ‚úÖ Smooth values with improved settings
        smooth_factor = config.vtube.smooth_factor
        self.smooth_values = {
            'FaceAngleX': SmoothValue(0, smooth_factor, 0.06),
            'FaceAngleY': SmoothValue(0, smooth_factor, 0.06),
            'FaceAngleZ': SmoothValue(0, smooth_factor, 0.06),
            'FacePositionX': SmoothValue(0, smooth_factor, 0.04),
            'FacePositionY': SmoothValue(0, smooth_factor, 0.04),
            'EyeLeftX': SmoothValue(0, smooth_factor, 0.08),
            'EyeLeftY': SmoothValue(0, smooth_factor, 0.08),
            'EyeRightX': SmoothValue(0, smooth_factor, 0.08),
            'EyeRightY': SmoothValue(0, smooth_factor, 0.08),
            'MouthOpen': SmoothValue(0, smooth_factor * 1.5, 0.15),  # ‚úÖ ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏≤‡∏Å
        }
        
        # Movement parameters
        self.movement_intensity = 0.8
        self.movement_speed = 1.0
        self.intensity_variation = 0.3
        
        # Timers
        self.last_movement_change = time.time()
        self.last_eye_movement = time.time()
        self.movement_duration = random.uniform(1.5, 3.0)
        self.eye_movement_duration = random.uniform(0.8, 2.0)
        
        # Lip sync state
        self._lip_sync_task: Optional[asyncio.Task] = None
        self._lip_sync_running: bool = False
        
        # ‚úÖ ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á parameter
        self._last_send_ts: float = 0.0
        self._min_send_interval: float = 0.040  # 40ms (25 FPS)
        self._last_sent_values: Dict[str, float] = {}
        self._send_threshold: float = 0.005  # ‚úÖ ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á > 0.5%
        
        # ‚úÖ Reconnect management
        self._reconnecting: bool = False
        self._last_reconnect_ts: float = 0.0
        self._reconnect_min_interval: float = 5.0
    
    async def connect(self) -> bool:
        """‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö VTube Studio"""
        try:
            from core.config import config
            
            logger.info("üì° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ VTube Studio...")
            
            self.ws = await websockets.connect(
                config.vtube.websocket_url,
                ping_interval=30,
                ping_timeout=60,
                close_timeout=5
            )
            logger.info("‚úÖ WebSocket ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            
            await self._authenticate()
            await self._get_current_model()
            
            if not self.model_loaded:
                logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏≠‡∏¢‡∏π‡πà")
                return False
            
            await self._get_available_parameters()
            
            # ‚úÖ ‡πÄ‡∏£‡∏¥‡πà‡∏° animation loop
            if not self.running or not self.animation_task or self.animation_task.done():
                self.running = True
                self.animation_task = asyncio.create_task(self._animation_loop())
            
            logger.info("‚úÖ VTube Studio ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ VTS ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}", exc_info=True)
            return False

    async def _ensure_ws(self) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢"""
        try:
            if self.ws and getattr(self.ws, 'open', False):
                return True

            now = time.time()
            if self._reconnecting or (now - self._last_reconnect_ts) < self._reconnect_min_interval:
                return False

            self._reconnecting = True
            self._last_reconnect_ts = now
            
            if self.ws:
                try:
                    await self.ws.close()
                except:
                    pass
                self.ws = None

            from core.config import config
            self.ws = await websockets.connect(
                config.vtube.websocket_url,
                ping_interval=30,
                ping_timeout=60,
                close_timeout=5
            )
            
            await self._authenticate()
            await self._get_current_model()
            
            if not self.model_loaded:
                self._reconnecting = False
                return False
                
            await self._get_available_parameters()
            
            logger.info("‚úÖ Reconnected VTS WebSocket")
            self._reconnecting = False
            return True
            
        except Exception as e:
            self._reconnecting = False
            logger.debug(f"Reconnect failed: {e}")
            return False
    
    async def _authenticate(self):
        """‡∏Ç‡∏≠ authentication"""
        try:
            from core.config import config
            
            if self.auth_token:
                auth_data = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "auth",
                    "messageType": "AuthenticationRequest",
                    "data": {
                        "pluginName": config.vtube.plugin_name,
                        "pluginDeveloper": "vioneyy",
                        "authenticationToken": self.auth_token
                    }
                }
            else:
                auth_data = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "auth_token_request",
                    "messageType": "AuthenticationTokenRequest",
                    "data": {
                        "pluginName": config.vtube.plugin_name,
                        "pluginDeveloper": "vioneyy"
                    }
                }
            
            await self.ws.send(json.dumps(auth_data))
            response = json.loads(await self.ws.recv())
            
            if "authenticationToken" in response.get("data", {}):
                self.auth_token = response["data"]["authenticationToken"]
                logger.info(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å token ‡∏ô‡∏µ‡πâ‡πÉ‡∏ô .env:")
                logger.info(f"VTS_PLUGIN_TOKEN={self.auth_token}")
                await self._authenticate()
                
            elif response.get("data", {}).get("authenticated"):
                self.authenticated = True
                logger.info("‚úÖ VTS Authentication ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            else:
                logger.warning(f"‚ö†Ô∏è Authentication ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {response}")
                
        except Exception as e:
            logger.error(f"‚ùå Authentication Error: {e}")
    
    async def _get_current_model(self):
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"""
        try:
            request = {
                "apiName": "VTubeStudioPublicAPI",
                "apiVersion": "1.0",
                "requestID": "get_model",
                "messageType": "CurrentModelRequest"
            }
            
            await self.ws.send(json.dumps(request))
            response = json.loads(await self.ws.recv())
            
            if response.get("data", {}).get("modelLoaded"):
                self.model_loaded = True
                self.model_id = response["data"]["modelID"]
                model_name = response["data"]["modelName"]
                logger.info(f"‚úÖ ‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
            else:
                logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏≠‡∏¢‡∏π‡πà")
                
        except Exception as e:
            logger.error(f"‚ùå Get Model Error: {e}")
    
    async def _get_available_parameters(self):
        """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ parameters ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ"""
        try:
            request = {
                "apiName": "VTubeStudioPublicAPI",
                "apiVersion": "1.0",
                "requestID": "get_params",
                "messageType": "InputParameterListRequest"
            }
            
            await self.ws.send(json.dumps(request))
            response = json.loads(await self.ws.recv())
            
            if response.get("data", {}).get("defaultParameters"):
                for param in response["data"]["defaultParameters"]:
                    param_name = param["name"]
                    self.available_parameters[param_name] = {
                        "min": param["min"],
                        "max": param["max"],
                        "value": param["value"]
                    }
                
                logger.info(f"üìã ‡∏û‡∏ö {len(self.available_parameters)} parameters")
                
                important = ['FaceAngleX', 'FaceAngleY', 'FaceAngleZ', 'MouthOpen']
                available_important = [p for p in important if p in self.available_parameters]
                if available_important:
                    logger.info(f"‚úÖ Parameters ‡∏ó‡∏µ‡πà‡∏°‡∏µ: {', '.join(available_important)}")
                    
        except Exception as e:
            logger.error(f"‚ùå Get Parameters Error: {e}")

    async def _send_parameters(self, parameters: Dict[str, float]):
        """‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á VTS (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á - ‡∏•‡∏î jitter)"""
        if not self.authenticated or not self.model_loaded or not self.ws:
            return

        try:
            if self.ws.state.name != 'OPEN':
                ok = await self._ensure_ws()
                if not ok:
                    return
        except Exception:
            pass

        # ‚úÖ Rate limiting - ‡∏™‡πà‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 25 FPS (40ms interval)
        now = time.time()
        if (now - self._last_send_ts) < self._min_send_interval:
            return

        try:
            valid_params = []
            
            # ‚úÖ Delta guard - ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏°‡∏≤‡∏Å‡∏û‡∏≠
            for param_name, value in parameters.items():
                if param_name not in self.available_parameters:
                    continue
                    
                param_info = self.available_parameters[param_name]
                clamped_value = max(param_info['min'], min(param_info['max'], value))
                
                last_val = self._last_sent_values.get(param_name, None)
                
                # ‚úÖ ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á > threshold
                if last_val is None or abs(clamped_value - last_val) >= self._send_threshold:
                    valid_params.append({
                        "id": param_name,
                        "value": clamped_value
                    })
                    self._last_sent_values[param_name] = clamped_value

            if not valid_params:
                return
            
            request = {
                "apiName": "VTubeStudioPublicAPI",
                "apiVersion": "1.0",
                "requestID": "inject_params",
                "messageType": "InjectParameterDataRequest",
                "data": {
                    "parameterValues": valid_params
                }
            }
            
            await asyncio.wait_for(
                self.ws.send(json.dumps(request)),
                timeout=0.5
            )
            
            self._last_send_ts = now
                
        except asyncio.TimeoutError:
            logger.debug("‚ö†Ô∏è Send timeout (ignored)")
        except Exception as e:
            if self.running:
                logger.error(f"‚ùå Send params error: {e}")
    
    def _generate_random_movement(self) -> Dict[str, float]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏∏‡∏î‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°"""
        from core.config import config
        
        intensity = random.uniform(0.6, 1.0) * self.movement_intensity
        
        angle_min, angle_max = config.vtube.head_rotation_range
        movements = {
            'FaceAngleX': random.uniform(angle_min, angle_max) * intensity,
            'FaceAngleY': random.uniform(angle_min, angle_max) * intensity,
            'FaceAngleZ': random.uniform(angle_min, angle_max) * intensity,
            'FacePositionX': random.uniform(-5, 5) * intensity * 0.5,
            'FacePositionY': 0,
            'EyeLeftX': random.uniform(-1, 1),
            'EyeLeftY': random.uniform(-0.7, 0.7),
            'EyeRightX': random.uniform(-1, 1),
            'EyeRightY': random.uniform(-0.7, 0.7)
        }
        
        return movements
    
    async def _animation_loop(self):
        """Loop ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß"""
        from core.config import config
        
        logger.info("üé¨ ‡πÄ‡∏£‡∏¥‡πà‡∏° Animation Loop")
        
        loop_count = 0
        
        while self.running:
            try:
                current_time = time.time()
                
                if loop_count % 100 == 0:
                    logger.debug(f"üîÑ Animation loop alive (iteration: {loop_count}, state: {self.state.value})")
                
                # ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ó‡πà‡∏≤ (‡πÑ‡∏°‡πà‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏Ç‡∏ì‡∏∞ speaking)
                if self.state != AnimationState.SPEAKING:
                    if current_time - self.last_movement_change >= self.movement_duration:
                        targets = self._generate_random_movement()
                        
                        for param_name, target_value in targets.items():
                            if param_name in self.smooth_values:
                                self.smooth_values[param_name].set_target(target_value)
                        
                        self.last_movement_change = current_time
                        self.movement_duration = random.uniform(1.5, 3.0) / self.movement_speed
                
                # ‚úÖ ‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏ï‡∏≤ (‡πÑ‡∏°‡πà‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏Ç‡∏ì‡∏∞ speaking)
                if self.state != AnimationState.SPEAKING:
                    if current_time - self.last_eye_movement >= self.eye_movement_duration:
                        eye_x = random.uniform(-1, 1)
                        eye_y = random.uniform(-0.7, 0.7)
                        
                        self.smooth_values['EyeLeftX'].set_target(eye_x)
                        self.smooth_values['EyeLeftY'].set_target(eye_y)
                        self.smooth_values['EyeRightX'].set_target(eye_x)
                        self.smooth_values['EyeRightY'].set_target(eye_y)
                        
                        self.last_eye_movement = current_time
                        self.eye_movement_duration = random.uniform(0.8, 2.0)
                
                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                current_values = {}
                for param_name, smooth_value in self.smooth_values.items():
                    current_values[param_name] = smooth_value.update()
                
                # ‡∏™‡πà‡∏á‡πÑ‡∏õ VTS
                await self._send_parameters(current_values)
                
                loop_count += 1
                
                # ‚úÖ ‡∏£‡∏≠ 50ms (20 FPS)
                await asyncio.sleep(config.vtube.idle_update_rate)
                
            except asyncio.CancelledError:
                logger.info("üõë Animation Loop cancelled")
                break
            except Exception as e:
                if self.running:
                    logger.error(f"‚ö†Ô∏è Animation error: {e}", exc_info=True)
                await asyncio.sleep(1)
        
        logger.info("üõë Animation Loop ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")

    async def start_lip_sync_from_file(self, audio_file_path: str):
        """‚úÖ Lip sync ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥"""
        if not self.authenticated or not self.model_loaded:
            logger.warning("‚ö†Ô∏è VTS not ready for lip sync")
            return
        if 'MouthOpen' not in self.available_parameters:
            logger.warning("‚ö†Ô∏è MouthOpen parameter not available")
            return

        logger.info(f"üé§ Starting improved lip sync: {audio_file_path}")

        async def _run():
            import wave
            import numpy as np
            try:
                self._lip_sync_running = True
                
                with wave.open(audio_file_path, 'rb') as wav:
                    sample_rate = wav.getframerate()
                    n_frames = wav.getnframes()
                    audio_bytes = wav.readframes(n_frames)
                    
                audio = np.frombuffer(audio_bytes, dtype=np.int16)
                
                # ‚úÖ ‡∏õ‡∏£‡∏±‡∏ö chunk size ‡πÉ‡∏´‡πâ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô (15ms) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏á‡∏Ñ‡πå‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
                chunk_ms = 15  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 10ms ‚Üí 15ms
                chunk_size = max(1, int(sample_rate * (chunk_ms / 1000.0)))
                
                ema = 0.0
                # ‚úÖ ‡∏õ‡∏£‡∏±‡∏ö attack/release ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
                attack = 0.85
                release = 0.70  # ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏¥‡∏î‡∏õ‡∏≤‡∏Å‡∏ó‡∏±‡∏ô
                
                # ‚úÖ Silence detection
                silence_threshold = 0.02  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.015
                silence_chunks_needed = 3  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 4
                silence_chunks = 0

                # ‚úÖ Hysteresis gate
                open_th = 0.20  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 0.22
                close_th = 0.10  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 0.12
                min_open_ms = 50  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 60
                min_close_ms = 30  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 40
                mouth_is_open = False
                time_since_open_ms = 0
                time_since_close_ms = 0

                # ‚úÖ Dynamic noise floor
                pre_samples = max(chunk_size, int(sample_rate * 0.2))
                pre = audio[:pre_samples].astype(np.float32)
                baseline_energy = 0.0
                if pre.size > 0:
                    norm_pre = pre / 32767.0
                    win_pre = np.hanning(norm_pre.size)
                    spec_pre = np.fft.rfft(norm_pre * win_pre)
                    freqs_pre = np.fft.rfftfreq(norm_pre.size, d=1.0 / sample_rate)
                    band_pre = (freqs_pre >= 300) & (freqs_pre <= 3400)
                    band_energy_pre = np.sqrt(np.mean(np.abs(spec_pre[band_pre]) ** 2)) if np.any(band_pre) else 0.0
                    rms_pre = float(np.sqrt(np.mean(norm_pre ** 2)))
                    baseline_energy = 0.7 * band_energy_pre + 0.3 * rms_pre

                # ‚úÖ ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏´‡∏¢‡∏∏‡∏î (‡∏û‡∏¢‡∏≤‡∏á‡∏Ñ‡πå)
                since_last_pause = 0.0
                pause_min = 0.10  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 0.12
                pause_max = 0.16  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 0.18
                next_pause_interval = random.uniform(pause_min, pause_max)

                last_mouth_value = 0.0

                for i in range(0, len(audio), chunk_size):
                    if not self._lip_sync_running:
                        break
                        
                    chunk = audio[i:i+chunk_size].astype(np.float32)
                    if chunk.size == 0:
                        continue
                        
                    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì volume ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (speech band 300-3400 Hz)
                    norm = chunk / 32767.0
                    win = np.hanning(norm.size)
                    spec = np.fft.rfft(norm * win)
                    freqs = np.fft.rfftfreq(norm.size, d=1.0 / sample_rate)
                    band = (freqs >= 300) & (freqs <= 3400)
                    band_energy = np.sqrt(np.mean(np.abs(spec[band]) ** 2)) if np.any(band) else 0.0
                    rms = float(np.sqrt(np.mean(norm ** 2)))
                    energy_raw = 0.7 * band_energy + 0.3 * rms
                    energy = max(0.0, energy_raw - baseline_energy * 1.1)
                    volume = min(energy * 2.2, 1.0)  # ‡πÄ‡∏û‡∏¥‡πà‡∏° gain ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
                    
                    # ‚úÖ ‡∏ô‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
                    if rms < silence_threshold:
                        silence_chunks += 1
                    else:
                        silence_chunks = 0
                    
                    # Smoothing
                    if volume > ema:
                        ema = attack * volume + (1 - attack) * ema
                    else:
                        ema = release * volume + (1 - release) * ema

                    # ‚úÖ Hysteresis gating
                    if mouth_is_open:
                        time_since_open_ms += chunk_ms
                        if ema < close_th and time_since_open_ms >= min_open_ms:
                            mouth_is_open = False
                            time_since_close_ms = 0
                    else:
                        time_since_close_ms += chunk_ms
                        if ema > open_th and time_since_close_ms >= min_close_ms:
                            mouth_is_open = True
                            time_since_open_ms = 0

                    base_mouth = ema
                    if mouth_is_open:
                        if base_mouth > 0.4:
                            variation = random.uniform(0.97, 1.06)
                            mouth_open = base_mouth * variation
                        else:
                            mouth_open = base_mouth
                    else:
                        mouth_open = 0.0

                    # ‚úÖ ‡∏õ‡∏¥‡∏î‡∏õ‡∏≤‡∏Å‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
                    if silence_chunks >= silence_chunks_needed:
                        mouth_open = 0.0
                        ema = max(0.0, ema * 0.5)
                        mouth_is_open = False
                        time_since_close_ms = 0
                    
                    mouth_open = max(0.0, min(1.0, mouth_open))
                    
                    # ‚úÖ ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏´‡∏¢‡∏∏‡∏î (‡∏û‡∏¢‡∏≤‡∏á‡∏Ñ‡πå)
                    since_last_pause += (chunk_size / sample_rate)
                    if since_last_pause >= next_pause_interval and mouth_open > 0.30:
                        mouth_open = max(0.0, mouth_open - 0.12)
                        since_last_pause = 0.0
                        next_pause_interval = random.uniform(pause_min, pause_max)

                    # ‚úÖ ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏°‡∏≤‡∏Å‡∏û‡∏≠
                    if abs(mouth_open - last_mouth_value) > 0.015:  # ‡∏•‡∏î threshold
                        await self.set_parameter_value('MouthOpen', mouth_open, immediate=False)
                        last_mouth_value = mouth_open
                        
                        # MouthForm
                        if 'MouthForm' in self.available_parameters:
                            await self.set_parameter_value('MouthForm', 0.0, immediate=False)
                        await asyncio.sleep(0.05)
                    logger.info("üëÑ Mouth closed")
                except Exception:
                    pass

        # ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏á‡∏≤‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        if self._lip_sync_task and not self._lip_sync_task.done():
            self._lip_sync_running = False
            self._lip_sync_task.cancel()
            try:
                await self._lip_sync_task
            except asyncio.CancelledError:
                pass
        
        self._lip_sync_task = asyncio.create_task(_run())

    async def set_parameter_value(self, param_name: str, value: float, immediate: bool = True):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß"""
        try:
            if param_name not in self.available_parameters:
                return
            info = self.available_parameters[param_name]
            clamped = max(info['min'], min(info['max'], value))
            
            # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó smooth target
            if param_name in self.smooth_values:
                self.smooth_values[param_name].set_target(clamped)

            # ‡∏™‡πà‡∏á‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            if immediate and self.authenticated and self.model_loaded:
                now = time.time()
                if (now - self._last_send_ts) < self._min_send_interval:
                    return
                ok = await self._ensure_ws()
                if not ok or not self.ws:
                    return
                req = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "inject_param_single",
                    "messageType": "InjectParameterDataRequest",
                    "data": {
                        "parameterValues": [{"id": param_name, "value": clamped}]
                    }
                }
                await self.ws.send(json.dumps(req))
                self._last_send_ts = now
                self._last_sent_values[param_name] = clamped
        except Exception as e:
            logger.debug(f"Set param error: {e}")
    
    async def start_speaking(self, text: str):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î"""
        logger.info(f"üó£Ô∏è Start speaking: {text[:50]}...")
        self.state = AnimationState.SPEAKING
    
    async def stop_speaking(self):
        """‚úÖ ‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ transition ‡∏Å‡∏•‡∏±‡∏ö idle ‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•"""
        logger.info("üõë Stop speaking")
        self._lip_sync_running = False
        
        # ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å lip sync task
        if self._lip_sync_task and not self._lip_sync_task.done():
            try:
                self._lip_sync_task.cancel()
                await self._lip_sync_task
            except asyncio.CancelledError:
                pass
        
        # ‚úÖ ‡∏õ‡∏¥‡∏î‡∏õ‡∏≤‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•
        if 'MouthOpen' in self.smooth_values:
            try:
                # Gradual close (4 steps)
                for val in [0.3, 0.15, 0.05, 0.0]:
                    self.smooth_values['MouthOpen'].set_target(val)
                    await asyncio.sleep(0.03)
            except Exception:
                pass
        
        # ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏•‡∏±‡∏ö idle
        self.state = AnimationState.IDLE
        
        # ‚úÖ ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï movement timers ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏° idle motion ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        self.last_movement_change = 0.0
        self.last_eye_movement = 0.0
        self.movement_duration = random.uniform(1.0, 2.0)
        self.eye_movement_duration = random.uniform(0.5, 1.0)
        
        logger.info("‚úÖ Transitioned back to IDLE")
    
    async def set_state(self, state: AnimationState):
        """‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞"""
        logger.debug(f"üéÆ State change: {self.state.value} ‚Üí {state.value}")
        self.state = state
        
        if state == AnimationState.THINKING:
            self.movement_intensity = 0.4
        else:
            self.movement_intensity = 0.8
        
        # ‚úÖ ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï timers ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏±‡∏ö idle
        if state == AnimationState.IDLE:
            self.last_movement_change = 0.0
            self.movement_duration = random.uniform(1.0, 2.0)
            self.last_eye_movement = 0.0
            logger.debug("üîÑ Timers reset for idle motion")
    
    async def set_talking(self, talking: bool):
        """‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏π‡∏î"""
        if talking:
            await self.set_state(AnimationState.SPEAKING)
        else:
            await self.stop_speaking()
    
    async def update_idle_motion(self):
        """‚úÖ ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó idle motion - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏ó‡∏±‡∏ô‡∏ó‡∏µ"""
        logger.info("üîÑ Updating idle motion")
        await self.set_state(AnimationState.IDLE)
        
        # ‚úÖ ‡∏™‡∏∏‡πà‡∏°‡∏ó‡πà‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        targets = self._generate_random_movement()
        for param_name, target_value in targets.items():
            if param_name in self.smooth_values:
                self.smooth_values[param_name].set_target(target_value)
        
        logger.info("‚úÖ Idle motion updated")
    
    async def disconnect(self):
        """‡∏ï‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠"""
        logger.info("üõë ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ VTS...")
        self.running = False
        
        if self.animation_task:
            self.animation_task.cancel()
            try:
                await self.animation_task
            except asyncio.CancelledError:
                pass
        
        if self.ws:
            try:
                await self.ws.close()
            except:
                pass
        
        logger.info("üëã ‡∏ï‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ VTS ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

    async def execute_motion_command(self, motion_cmd):
        """‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á motion"""
        from core.motion_commands import MotionType

        if not self.authenticated or not self.model_loaded:
            logger.warning("‚ö†Ô∏è VTS not ready for motion")
            return

        logger.info(f"üé≠ Executing motion: {motion_cmd.motion_type.value}")

        try:
            if motion_cmd.motion_type == MotionType.THINKING:
                await self._motion_thinking(motion_cmd)
            elif motion_cmd.motion_type == MotionType.EXCITED:
                await self._motion_excited(motion_cmd)
            elif motion_cmd.motion_type == MotionType.CONFUSED:
                await self._motion_confused(motion_cmd)
            elif motion_cmd.motion_type == MotionType.HAPPY:
                await self._motion_happy(motion_cmd)
            elif motion_cmd.motion_type == MotionType.SAD:
                await self._motion_sad(motion_cmd)
            elif motion_cmd.motion_type == MotionType.ANGRY:
                await self._motion_angry(motion_cmd)
            else:
                await self._motion_idle()
        except Exception as e:
            logger.error(f"‚ùå Motion execution error: {e}")

    async def _motion_thinking(self, motion_cmd):
        """‡∏Ñ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà"""
        intensity = motion_cmd.intensity.value
        targets = {
            'FaceAngleX': 5.0 * intensity,
            'FaceAngleY': 0.0,
            'FaceAngleZ': 0.0,
            'EyeLeftY': -0.3 * intensity,
            'EyeRightY': -0.3 * intensity,
        }
        for param_name, target_value in targets.items():
            if param_name in self.smooth_values:
                self.smooth_values[param_name].set_target(target_value)
        await asyncio.sleep(motion_cmd.duration)
        await self._motion_idle()

    async def _motion_excited(self, motion_cmd):
        """‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô"""
        intensity = motion_cmd.intensity.value
        targets = {
            'FaceAngleX': -8.0 * intensity,
            'FaceAngleY': float(random.choice([-15, 15])) * intensity,
            'FaceAngleZ': float(random.choice([-8, 8])) * intensity,
            'EyeLeftX': float(random.uniform(-1, 1)),
            'EyeLeftY': float(random.uniform(-0.5, 0.5)),
            'EyeRightX': float(random.uniform(-1, 1)),
            'EyeRightY': float(random.uniform(-0.5, 0.5)),
        }
        for param_name, target_value in targets.items():
            if param_name in self.smooth_values:
                self.smooth_values[param_name].set_target(target_value)
        
        elapsed = 0.0
        while elapsed < motion_cmd.duration:
            if motion_cmd.micro_twitch_enabled and elapsed % 0.5 < 0.25:
                twitch = self._generate_random_micro_twitch()
                for key in twitch:
                    if key in self.smooth_values:
                        current_target = self.smooth_values[key].target
                        self.smooth_values[key].set_target(current_target + twitch[key] * 0.3)
            await asyncio.sleep(0.05)
            elapsed += 0.05
        await self._motion_idle()

    def _generate_random_micro_twitch(self) -> Dict[str, float]:
        """‡∏™‡∏∏‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏±‡∏ö‡πÄ‡∏•‡πá‡∏Å ‡πÜ"""
        return {
            'FaceAngleX': random.uniform(-2, 2),
            'FaceAngleY': random.uniform(-3, 3),
            'FaceAngleZ': random.uniform(-2, 2),
        }

    async def _motion_confused(self, motion_cmd):
        """‡∏á‡∏á‡πÜ"""
        intensity = motion_cmd.intensity.value
        targets = {
            'FaceAngleX': float(random.uniform(-3, 3)),
            'FaceAngleY': 15.0 * intensity,
            'FaceAngleZ': 8.0 * intensity,
            'EyeLeftX': -0.5,
            'EyeLeftY': 0.2,
            'EyeRightX': 0.5,
            'EyeRightY': -0.2,
        }
        for param_name, target_value in targets.items():
            if param_name in self.smooth_values:
                self.smooth_values[param_name].set_target(target_value)
        
        elapsed = 0.0
        while elapsed < motion_cmd.duration:
            if elapsed % 0.3 < 0.15:
                self.smooth_values['EyeLeftY'].set_target(-0.5)
                self.smooth_values['EyeRightY'].set_target(-0.5)
            else:
                self.smooth_values['EyeLeftY'].set_target(0.2)
                self.smooth_values['EyeRightY'].set_target(-0.2)
            await asyncio.sleep(0.05)
            elapsed += 0.05
        await self._motion_idle()

    async def _motion_happy(self, motion_cmd):
        """‡∏¢‡∏¥‡πâ‡∏°"""
        intensity = motion_cmd.intensity.value
        elapsed = 0.0
        while elapsed < motion_cmd.duration:
            angle_y = 10.0 * intensity * abs(float(np.sin(elapsed * 2 * np.pi / 1.0)))
            self.smooth_values['FaceAngleY'].set_target(angle_y)
            await asyncio.sleep(0.1)
            elapsed += 0.1
        await self._motion_idle()

    async def _motion_sad(self, motion_cmd):
        """‡πÄ‡∏®‡∏£‡πâ‡∏≤"""
        intensity = motion_cmd.intensity.value
        targets = {
            'FaceAngleX': 10.0 * intensity,
            'FaceAngleY': 0.0,
            'FaceAngleZ': 0.0,
            'EyeLeftY': -0.5 * intensity,
            'EyeRightY': -0.5 * intensity,
        }
        for param_name, target_value in targets.items():
            if param_name in self.smooth_values:
                self.smooth_values[param_name].set_target(target_value)
        await asyncio.sleep(motion_cmd.duration)
        await self._motion_idle()

    async def _motion_angry(self, motion_cmd):
        """‡πÇ‡∏Å‡∏£‡∏ò"""
        intensity = motion_cmd.intensity.value
        targets = {
            'FaceAngleX': -10.0 * intensity,
            'FaceAngleY': 0.0,
            'FaceAngleZ': float(random.choice([-1, 1])) * 5.0 * intensity,
        }
        for param_name, target_value in targets.items():
            if param_name in self.smooth_values:
                self.smooth_values[param_name].set_target(target_value)
        await asyncio.sleep(motion_cmd.duration)
        await self._motion_idle()

    async def _motion_idle(self):
        """‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô idle"""
        targets = self._generate_random_movement()
        for param_name, target_value in targets.items():
            if param_name in self.smooth_values:
                self.smooth_values[param_name].set_target(target_value)

# Global controller
vtube_controller = VTubeStudioController()
                            if mouth_open > 0.6:
                                mouth_form = random.uniform(0.6, 0.8)
                            elif mouth_open > 0.3:
                                mouth_form = random.uniform(0.3, 0.5)
                            else:
                                mouth_form = 0.0
                            await self.set_parameter_value('MouthForm', mouth_form, immediate=False)
                    
                    await asyncio.sleep(chunk_size / sample_rate)
                
                logger.info("‚úÖ Lip sync completed")
                
            except Exception as e:
                logger.error(f"‚ùå Lip sync error: {e}", exc_info=True)
            finally:
                self._lip_sync_running = False
                
                # ‚úÖ ‡∏õ‡∏¥‡∏î‡∏õ‡∏≤‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•
                try:
                    for val in [0.4, 0.2, 0.0]:
                        await self.set_parameter_value('MouthOpen', val, immediate=False)
                        if 'MouthForm' in self.available_parameters: